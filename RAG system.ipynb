{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### –°–∏—Å—Ç–µ–º–∞ Retrieval-Augmented Generation (RAG) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LangChain ü¶úüîó\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "N6jXUO3qoLZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qYsmapGGY08y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–æ–±—Ö–æ–¥–∏–º–æ–µ\n",
        "\n"
      ],
      "metadata": {
        "id": "WfG9uui8kZ8k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCVDjkLGX5s1",
        "outputId": "7fef02c8-f399-48c3-f6f7-f7c329767422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.5-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.13 (from langchain)\n",
            "  Downloading langchain_core-0.3.13-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.13->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.13->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading langchain-0.3.5-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.13-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m408.0/408.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.1-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, orjson, mypy-extensions, marshmallow, jsonpointer, jiter, h11, faiss-cpu, typing-inspect, requests-toolbelt, jsonpatch, httpcore, pydantic-settings, httpx, dataclasses-json, openai, langsmith, sentence-transformers, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.9.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.5 langchain-core-0.3.13 langchain-text-splitters-0.3.1 langchain_community-0.3.3 langsmith-0.1.137 marshmallow-3.23.0 mypy-extensions-1.0.0 openai-1.52.2 orjson-3.10.10 pydantic-settings-2.6.0 python-dotenv-1.0.1 requests-toolbelt-1.0.0 sentence-transformers-3.2.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain faiss-cpu transformers sentence-transformers huggingface_hub langchain_community openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cte5Md4Hm3Pm",
        "outputId": "0b0db232-a4f1-4d93-e80f-cf42aab05070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Gosha69228/TEXT.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j5NBwKuom9OV",
        "outputId": "78418f66-2f8c-4ab5-dda6-d3cdab7f69c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TEXT'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 57 (delta 20), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (57/57), 50.33 KiB | 831.00 KiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –î–µ–ª–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö\n",
        "\n",
        "---\n",
        "–ü—Ä–æ—à—É –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ñ–∞–π–ª TEST_FILE.txt, —ç—Ç–æ—Ç —Ñ–∞–π–ª —Å–æ–∂–µ—Ä–∂–∏—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –≤—ã–¥—É–º–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –§–∞–π–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ–≥–æ, —á—Ç–æ –º–æ–¥–µ–ª—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–µ–π—Å—Ç–≤–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π. (–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –º–æ–∂–Ω–æ –≤–≤–æ–¥–∏—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏ –ø–æ —Ç–µ–º–µ –ò–ë). –í—Å–µ —Å—Ç–∞—Ç—å–∏ –ø–æ –ò–ë –≤–∑—è—Ç—ã —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞ –ö–∞—Å–ø–µ—Ä—Å–∫–æ–≥–æ –∏ SecurityLab: https://encyclopedia.kaspersky.ru/glossary/insider-threat/ –∏ https://www.securitylab.ru/analytics/\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º—Ç–æ–≤ –¥–ª—è —Ñ–∞–π–ª–∞ TEST_FILE.txt:\n",
        "\n",
        "1) \"–ö–∞–∫ –∑–∞—â–∏—Ç–∏—Ç—å —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ –æ—Ç –∑–ª–æ–±–Ω—ã—Ö –µ–¥–∏–Ω–æ—Ä–æ–≥–æ–≤ –∏ –∫–æ—Å–º–∏—á–µ—Å–∫–∏—Ö –º—ã—à–µ–π\"\n",
        "\n",
        "2) \"–ó–∞—á–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–µ –ø–∞—Ä–æ–ª–∏?\"\n",
        "\n",
        "3) \"–ü–µ—Ä–µ–¥ —á–µ–º –Ω–µ –º–æ–≥—É—Ç —É—Å—Ç–æ—è—Ç—å –µ–¥–∏–Ω–æ—Ä–æ–≥–∏\"\n"
      ],
      "metadata": {
        "id": "RnisKpwfke5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('knowledge_base.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS articles (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    title TEXT,\n",
        "    content TEXT\n",
        ")\n",
        "''')\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "2Tq-y9aha_Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "repo_path = '/content/TEXT'\n",
        "\n",
        "for filename in os.listdir(repo_path):\n",
        "    if filename.endswith('.txt'):\n",
        "        with open(os.path.join(repo_path, filename), 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "            title = filename[:-4]\n",
        "            cursor.execute('INSERT INTO articles (title, content) VALUES (?, ?)', (title, content))\n",
        "\n",
        "conn.commit()\n"
      ],
      "metadata": {
        "id": "LUHZJ-NkqBaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é —Å–ø–ª–∏—Ç–µ—Ä–∞ –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã**"
      ],
      "metadata": {
        "id": "8NaX5AZvmW8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "OKQZvJVJ4ioK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap  = 700,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")"
      ],
      "metadata": {
        "id": "waJuOhpf45jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(\"SELECT id, content FROM articles\")\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "all_chunks = []\n",
        "\n",
        "for row in rows:\n",
        "    article_id, content = row\n",
        "\n",
        "    texts = text_splitter.create_documents([content])\n",
        "\n",
        "    all_chunks.extend(texts)"
      ],
      "metadata": {
        "id": "eTWgGwbK6RT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º –∫–∞–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —É –Ω–∞—Å –ø–æ–ª—É—á–∏–ª–∏—Å—å.\n",
        "\n",
        "–í all_chunks[0-208]"
      ],
      "metadata": {
        "id": "vfrLDf2InKcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_chunks[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V59Fo2BwBubw",
        "outputId": "99348c9e-a2fd-41ed-cf78-3786565bc146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ò–Ω—Å–∞–π–¥–µ—Ä—Å–∫–∞—è —É–≥—Ä–æ–∑–∞ ‚Äî —Ä–∏—Å–∫ –ø—Ä–∏—á–∏–Ω–µ–Ω–∏—è —É—â–µ—Ä–±–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –ª—é–¥—å–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç—É—Ä–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ö —Ç–∞–∫–∏–º –ª—é–¥—è–º ‚Äî –∏—Ö –Ω–∞–∑—ã–≤–∞—é—Ç –∏–Ω—Å–∞–π–¥–µ—Ä–∞–º–∏ ‚Äî –º–æ–≥—É—Ç –æ—Ç–Ω–æ—Å–∏—Ç—å—Å—è –∫–∞–∫ –±—ã–≤—à–∏–µ –∏–ª–∏ –¥–µ–π—Å—Ç–≤—É—é—â–∏–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ —Å–∞–º–æ–π –∫–æ–º–ø–∞–Ω–∏–∏, —Ç–∞–∫ –∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã –ø–æ–¥—Ä—è–¥—á–∏–∫–æ–≤ –∏–ª–∏ –ø–∞—Ä—Ç–Ω–µ—Ä—ã, —Ç–æ –µ—Å—Ç—å –≤—Å–µ, –∫—Ç–æ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∫–æ–º–ø–∞–Ω–∏–∏.\n",
            "\n",
            "–ò–Ω—Å–∞–π–¥–µ—Ä—ã –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞–∫ –∑–ª–æ–Ω–∞–º–µ—Ä–µ–Ω–Ω—ã–º–∏, —Ç–∞–∫ –∏ –ø—Ä–æ—Å—Ç–æ –Ω–µ–æ—Å—Ç–æ—Ä–æ–∂–Ω—ã–º–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, —Å–æ—Ç—Ä—É–¥–Ω–∏–∫, –ø–æ—Ç–µ—Ä—è–≤—à–∏–π —Ñ–ª–µ—à–∫—É —Å —Å–µ–∫—Ä–µ—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, ‚Äî —Ç–æ–∂–µ –∏–Ω—Å–∞–π–¥–µ—Ä. –ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–Ω—Å–∞–π–¥–µ—Ä–æ–≤ —Ä–∞—Å—Å–∫–∞–∑–∞–Ω–æ –≤ ¬´–ë–∞–∑–µ –∑–Ω–∞–Ω–∏–π¬ª.\n",
            "\n",
            "–û–ø–∞—Å–Ω–æ—Å—Ç—å –∏–Ω—Å–∞–π–¥–µ—Ä—Å–∫–æ–π —É–≥—Ä–æ–∑—ã\n",
            "–ò–Ω—Å–∞–π–¥–µ—Ä—ã –∏–º–µ—é—Ç –ª–µ–≥–∏—Ç–∏–º–Ω—ã–π –¥–æ—Å—Ç—É–ø –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—É—é —Å–µ—Ç—å –∫–æ–º–ø–∞–Ω–∏–∏, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–µ–Ω –∏–º, —á—Ç–æ–±—ã –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å–≤–æ–∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏, –∏ —Å—Ä–µ–¥—Å—Ç–≤–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –Ω–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç –∏—Ö –∫–∞–∫ —É–≥—Ä–æ–∑—É. –ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º, –∏–º –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤–∑–ª–∞–º—ã–≤–∞—Ç—å —á—É–∂–∏–µ –∞–∫–∫–∞—É–Ω—Ç—ã –∏ –æ–±—Ö–æ–¥–∏—Ç—å —Å—Ä–µ–¥—Å—Ç–≤–∞ –∑–∞—â–∏—Ç—ã –ø–µ—Ä–∏–º–µ—Ç—Ä–∞ (–º–µ–∂—Å–µ—Ç–µ–≤—ã–µ —ç–∫—Ä–∞–Ω—ã –∏ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã). –ò—Å–ø–æ–ª—å–∑—É—è —Å–≤–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ, –∏–Ω—Å–∞–π–¥–µ—Ä—ã –º–æ–≥—É—Ç –∏–∑—É—á–∏—Ç—å –¥–µ–π—Å—Ç–≤—É—é—â–∏–µ –≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —É–∑–Ω–∞—Ç—å –∏—Ö —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞.\n",
            "\n",
            "–ö–∞–∫–æ–π –≤—Ä–µ–¥ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –º–æ–∂–µ—Ç –Ω–∞–Ω–µ—Å—Ç–∏ –∏–Ω—Å–∞–π–¥–µ—Ä:\n",
            "\n",
            "–£–∫—Ä–∞—Å—Ç—å –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –ø–µ—Ä–µ–¥–∞—Ç—å –µ–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º.\n",
            "–û–±–Ω–∞—Ä–æ–¥–æ–≤–∞—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø–æ–¥–ø–∞–¥–∞—é—â–∏–µ –ø–æ–¥ –¥–µ–π—Å—Ç–≤–∏–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–≥–ª–∞–º–µ–Ω—Ç–æ–≤.\n",
            "–£–Ω–∏—á—Ç–æ–∂–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—É—é –¥–ª—è —Ä–∞–±–æ—Ç—ã –∫–æ–º–ø–∞–Ω–∏–∏.\n",
            "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã.\n",
            "–û—Ç–∫–ª—é—á–∏—Ç—å –∏–ª–∏ –≤—ã–≤–µ—Å—Ç–∏ –∏–∑ —Å—Ç—Ä–æ—è –ò–ë-—Å–∏—Å—Ç–µ–º—ã –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –≤–Ω–µ—à–Ω–µ–π –∞—Ç–∞–∫–∏.\n",
            "–ß–∞—â–µ –≤—Å–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –∏–Ω—Å–∞–π–¥–µ—Ä–æ–≤ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ —É—Ç–µ—á–∫–µ –¥–∞–Ω–Ω—ã—Ö.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º **–º–æ–¥–µ–ª—å** –∏ **–≤–µ–∫—Ç–æ—Ä–Ω–æ–µ** **—Ö—Ä–∞–Ω–∏–ª–∏—â–µ**"
      ],
      "metadata": {
        "id": "M-uTXQ4upMlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "k1kROCoEnSvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–¢—É—Ç –Ω–∞–¥–æ –≤—Å—Ç–∞–≤–∏—Ç—å —Å–≤–æ–π –∫–ª—é—á, –æ—Ç OpenAI API, –Ω–∞ –º–æ–µ–º –±–∞–ª–∞–Ω—Å –Ω–µ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π ‚òπ"
      ],
      "metadata": {
        "id": "xmRn3AvFpp-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_key = '' #–Ω—É–∂–µ–Ω –∫–ª—é—á–∏–∫ (—Ç–æ–∫–µ–Ω)"
      ],
      "metadata": {
        "id": "ZBDOjDIFpIN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatOpenAI(openai_api_key=openai_key, model_name=\"gpt-3.5-turbo-1106\", temperature=0.0)\n",
        "\n"
      ],
      "metadata": {
        "id": "c6uEOHKiL2Sj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3040a51d-5407-43d2-f078-73450082fa27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-badbb24d577f>:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chat_model = ChatOpenAI(openai_api_key=openai_key, model_name=\"gpt-3.5-turbo-1106\", temperature=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "easy_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", '{question}'),\n",
        "])"
      ],
      "metadata": {
        "id": "5Tl6S_mwDZ_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–î–µ–ª–∞–µ–º –ø—Ä–æ–±–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ –±–µ–∑ RAG, –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ (–æ—Ç–≤–µ—Ç \"res\" –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ —Ñ–∞–π–ª–∞ TEST_FILE.txt)\n",
        "\n",
        "–ú–æ–¥–µ–ª—å ChatGPT –¥–æ–≤–æ–ª—å–Ω–æ \"—É–º–Ω–∞—è\" –∏ –Ω–∞ –±–∞–Ω–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–º–µ –ò–ë –æ—Ç–≤–µ—á–∞–µ—Ç –≤–ø–æ–ª–Ω–µ –Ω–µ–ø–ª–æ—Ö–æ, —Ç—è–∂–µ–ª–æ –æ—Ç–ª–∏—á–∏—Ç—å –µ–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–∞—Ö. –î–ª—è —ç—Ç–æ–≥–æ –∏ —Å–æ–∑–¥–∞–Ω TEST_FILE.txt, –≤ –Ω–µ–º —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤—ã–¥—É–º–∞–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –∫–æ—Ç–æ—Ä—É—é –º–æ–¥–µ–ª—å, –Ω–∞–≤—Ä—è—Ç–ª–∏, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç, –Ω–µ –æ–±—Ä–∞—â–∞—è—Å—å –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π."
      ],
      "metadata": {
        "id": "KoRjLIbHqDXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = '–ü–µ—Ä–µ–¥ —á–µ–º –Ω–µ –º–æ–≥—É—Ç —É—Å—Ç–æ—è—Ç—å –µ–¥–∏–Ω–æ—Ä–æ–≥–∏'"
      ],
      "metadata": {
        "id": "6QT_Oq8EMbGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = easy_prompt | chat_model"
      ],
      "metadata": {
        "id": "afUR8vPjMd2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = chain1.invoke({'question': query})"
      ],
      "metadata": {
        "id": "NF1udJnQMgey",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "ef8f7b41-d865-476c-cc33-410a99488ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-35988661e4ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         return cast(\n\u001b[1;32m    285\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    785\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         flattened_outputs = [\n\u001b[1;32m    645\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 results.append(\n\u001b[0;32m--> 633\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    634\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    852\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/chat_models/openai.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         }\n\u001b[0;32m--> 475\u001b[0;31m         response = self.completion_with_retry(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/chat_models/openai.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;34m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_openai_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mretry_decorator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_retry_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    813\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    816\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         )\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    955\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1044\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1044\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "A7Os16DhMh7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –∏–Ω–¥–µ–∫—Å**"
      ],
      "metadata": {
        "id": "CjtATn_drzec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# –í—ã–±–∏—Ä–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ CUDA, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë, –∏–Ω–∞—á–µ - CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_kwargs = {'device': device}\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"cointegrated/LaBSE-en-ru\", model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)\n",
        "\n",
        "db = FAISS.from_documents(all_chunks, embeddings)"
      ],
      "metadata": {
        "id": "ryhZOCXxx2s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ù–∞—à –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å**"
      ],
      "metadata": {
        "id": "QOUtLaR9sC_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = '–ú–µ—Ç–æ–¥—ã –∑–∞—â–∏—Ç—ã –æ—Ç DDoS-–∞—Ç–∞–∫?'"
      ],
      "metadata": {
        "id": "cqPWfuokaXMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = '–ü–µ—Ä–µ–¥ —á–µ–º –Ω–µ –º–æ–≥—É—Ç —É—Å—Ç–æ—è—Ç—å –µ–¥–∏–Ω–æ—Ä–æ–≥–∏'"
      ],
      "metadata": {
        "id": "54b4de69z9JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = db.similarity_search(query)"
      ],
      "metadata": {
        "id": "ezaVUp9wwLsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ú–æ–∂–µ–º –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∫—É—Å–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö(–∫–æ—Ç–æ—Ä—ã–µ –º—ã —Å–ø–ª–∏—Ç–∏–ª–∏), –∫–æ—Ç–æ—Ä—ã–µ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –ø–æ–¥—Ö–æ–¥—è—Ç –ø–æ–¥ –∑–∞–ø—Ä–æ—Å** (*docs[0-3]*)"
      ],
      "metadata": {
        "id": "-zdFxfXNsNya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[3].page_content)"
      ],
      "metadata": {
        "id": "GpZXmWN_0Dsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç"
      ],
      "metadata": {
        "id": "7DlvTYkusvaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_text = \"\"\"–¢—ã —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏,\n",
        "–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É—é—â–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∑–∞—â–∏—Ç—ã –¥–∞–Ω–Ω—ã—Ö.\n",
        " –í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤—ã–¥–µ—Ä–∂–∫–∏ –∏–∑ —Å—Ç–∞—Ç–µ–π –∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤, –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ç–æ—Ä—ã—Ö —Ç—ã –¥–æ–ª–∂–µ–Ω –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n",
        "–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞–π–¥–µ–Ω, —É–∫–∞–∂–∏ –∏–∑ –∫–∞–∫–æ–π —Å—Ç–∞—Ç—å–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç.\n",
        "–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å, –æ—Ç–≤–µ—á–∞–π, —á—Ç–æ —É —Ç–µ–±—è –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–æ–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n",
        "–ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ —Ç–æ–∫–∞–∫ –∑–ª–æ–º–∞—Ç—å –ø–µ–Ω—Ç–∞–≥–æ–Ω, –æ—Ç–≤–µ—á–∞–π —Ç–∞–∫ –∫–∞–∫ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, —à—É—Ç–æ—á–Ω–æ\n",
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kxud-_GdSl1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt_text),\n",
        "    (\"human\", '{question}'),\n",
        "])\n",
        "\n",
        "chat_prompt"
      ],
      "metadata": {
        "id": "7R2BISX3TPgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º retriever, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏–∑–≤–ª–µ–∫–∞—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"
      ],
      "metadata": {
        "id": "P2Hba9N3tXyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uYu8ad5D6NZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever(search_kwargs={\"k\": 10})"
      ],
      "metadata": {
        "id": "pvncqi1VO-pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs3 = retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "yBy716yXOTDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ú–æ–∂–µ–º –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–∫–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤ —Ä–µ—Ç—Ä–∏–≤–µ—Ä –Ω–∞—à–µ–ª, –∏ –∫–∞–∫–∏–µ"
      ],
      "metadata": {
        "id": "B2NEO93LtgTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs3)"
      ],
      "metadata": {
        "id": "_W_Wa_blQRCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs3[9]"
      ],
      "metadata": {
        "id": "ufossHI5QRFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain.prompts.pipeline import PipelinePromptTemplate"
      ],
      "metadata": {
        "id": "7t69szheQRH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.output_parser import BaseLLMOutputParser"
      ],
      "metadata": {
        "id": "KzyaFO6ZQ5Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ï—â–µ –æ–¥–∏–Ω —à–∞–±–ª–æ–Ω–Ω—ã–π –ø—Ä–æ–º—Ç –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–æ–º—Ç–æ–≤."
      ],
      "metadata": {
        "id": "9TCcIpbWt_Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyde_prompt = PromptTemplate.from_template(\"\"\"\n",
        "–¢—ã —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ö —Ç–µ–±–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –±—ã—Ç–æ–≤–æ–º —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ–º —è–∑—ã–∫–µ.\n",
        "–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —è–∑—ã–∫, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –Ω–∞–π—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –Ω—É–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.\n",
        "–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: –∫–∞–∫ –∑–∞—â–∏—Ç–∏—Ç—å—Å—è –æ—Ç –≤–∑–ª–æ–º–∞ Wi-Fi?\n",
        "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å: –º–µ—Ç–æ–¥—ã –∑–∞—â–∏—Ç—ã –±–µ—Å–ø—Ä–æ–≤–æ–¥–Ω–æ–π —Å–µ—Ç–∏ –æ—Ç –Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞?\n",
        "–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: —á—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ —Å–∫–∞—á–∞–ª –≤–∏—Ä—É—Å?\n",
        "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å: –¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω–æ–≥–æ –ü–û –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ?\n",
        "–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}\n",
        "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å:\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "uX0Y9RflQpao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ù–∞ –¥–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ, –∫–∞–∫ –º—ã –≤–∏–¥–∏–º, –º–æ–¥–µ–ª—å –ø–µ—Ä–µ—Å—Ç–∞–ª–∞ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Ç–µ–º—É, –Ω–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é –ø–æ–¥ —Ç–µ–º—É –ò–ë. –û–¥–Ω–∞–∫–æ, –æ–Ω–∞ –µ—â–µ –Ω–µ –≤–∏–¥–µ–ª–∞ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π üëÄ"
      ],
      "metadata": {
        "id": "6RC0S-zUuXqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query"
      ],
      "metadata": {
        "id": "-CXD_cRyQs1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_hyde = hyde_prompt | chat_model | StrOutputParser()"
      ],
      "metadata": {
        "id": "V8UeMwmHQuWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res1 = chain_hyde.invoke({'question': query})\n",
        "res1"
      ],
      "metadata": {
        "id": "J677Tjk_QyAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å –≤–æ–ø—Ä–æ—Å–æ–º –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º"
      ],
      "metadata": {
        "id": "qdOCSD82vy8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug_question = PromptTemplate.from_template('{question} {generated}')"
      ],
      "metadata": {
        "id": "rePPVkqZRgZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt_text),\n",
        "    (\"human\", '{question}'),\n",
        "])"
      ],
      "metadata": {
        "id": "ejcrPYuvRgcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_data = aug_question.format(question=query, generated=res1)\n",
        "aug_data"
      ],
      "metadata": {
        "id": "ce0_UrjLRgfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs = retriever.get_relevant_documents(aug_data)[:3]"
      ],
      "metadata": {
        "id": "Xe6mz98ARghJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs[0]"
      ],
      "metadata": {
        "id": "S7T1ptOORgju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt.format(context=retrieved_docs, question=query)"
      ],
      "metadata": {
        "id": "6Ne4P0vSRgmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–∞—è —Ü–µ–ø–æ—á–∫–∞, —Å–æ –≤—Å–µ–π –ª–æ–≥–∏–∫–æ–π\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "K9_RhXTiu75u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = (chat_prompt | chat_model | StrOutputParser())"
      ],
      "metadata": {
        "id": "r2dfR2MtRgod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = chain2.invoke({'context': retrieved_docs, 'question': query})"
      ],
      "metadata": {
        "id": "r-TE7tv8RgrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π. –ö–∞–∫ –º—ã –≤–∏–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ —Ñ–∞–π–ª–∞ TEST_FILE.txt**"
      ],
      "metadata": {
        "id": "FLBYur71vLox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "MSXDy4voRgtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query #—Å—É—â–µ—Å—Ç–≤—É—é –ª–∏ –µ–¥–∏–Ω–æ—Ä–æ–≥–∏"
      ],
      "metadata": {
        "id": "2zx0CYhKRgwT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}